{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP(object):\n",
    "    def __init__(self ,num_inputs = 3, hidden_layers = [3, 3], num_outputs = 2):\n",
    "        self.num_inputs = num_inputs\n",
    "        self.hidden_layers = hidden_layers\n",
    "        self.num_outputs = num_outputs\n",
    "        \n",
    "        #create a representation of the layers\n",
    "        layers = [num_inputs] + hidden_layers + [num_outputs]\n",
    "        \n",
    "        #create random connection weights for the layers \n",
    "        weights = []\n",
    "        for i in range(len(layers) - 1):\n",
    "            w = np.random.rand(layers[i], layers[i + 1])\n",
    "            weights.append(w)\n",
    "        self.weights = weights\n",
    "        \n",
    "        #save derivates per layer\n",
    "        derivatives = []\n",
    "        for i in range(len(layers) - 1):\n",
    "            d = np.zeros((layers[i], layers[i+1]))\n",
    "            derivatives.append(d)\n",
    "        self.derivatives = derivatives\n",
    "        \n",
    "        #save activations per layer\n",
    "        activations = []\n",
    "        \n",
    "        for i in range(len(layers)):\n",
    "            a = np.zeros(layers[i])\n",
    "            activations.append(a)\n",
    "        self.activations = activations\n",
    "        \n",
    "    def forward_propagte(self,inputs):\n",
    "        #input layer activation is just the input itself\n",
    "        activations = inputs \n",
    "        \n",
    "        #save the activations for backpropogations\n",
    "        self.activations[0] = activations\n",
    "        \n",
    "        #iter through the network layers\n",
    "        for i,w in enumerate(self.weights):\n",
    "            #calculate matrix multiplications btw previous activations and weight matrixs\n",
    "            net_inputs = np.dot(activations, w)\n",
    "            \n",
    "            #apply sigmoid activation function\n",
    "            activations = self.sigmoid(net_inputs)\n",
    "            \n",
    "            #save the activations for backpropogation\n",
    "            self.activations[i + 1] = activations\n",
    "        #return output layer activation \n",
    "        return activations\n",
    "    \n",
    "    def back_propagate(self, error):\n",
    "        \n",
    "        #iter in backward in network layers\n",
    "        for i in reversed(range(len(self.derivatives))):\n",
    "            \n",
    "            #get activations for previous layer\n",
    "            activations = self.activations[i + 1]\n",
    "            \n",
    "            #apply sigmoid derivative function\n",
    "            delta = error*self.sigmoid_derivate(activations)\n",
    "            \n",
    "            #reshape fuction as a 2d array\n",
    "            delta_re = delta.reshape(delta.shape[0], -1).T\n",
    "            \n",
    "            #get activation for current layer\n",
    "            current_activations = self.activations[i]  # --> [1,3,4,5] --> [[1],[2],[3],[4]]\n",
    "            \n",
    "            #reshape activation as 2d col matrix\n",
    "            current_activations = current_activations.reshape(current_activations.shape[0], -1)\n",
    "            \n",
    "            #save derivate after applying matrix multiplications\n",
    "            self.derivatives[i] = np.dot(current_activations,delta_re)\n",
    "            \n",
    "            #backpropagate the next error\n",
    "            error = np.dot(delta, self.weights[i].T)\n",
    "    \n",
    "    def sigmoid(self, x):\n",
    "        y = 1.0/(1 + np.exp(-x))\n",
    "        return y\n",
    "    \n",
    "    def sigmoid_derivate(self, x):\n",
    "        return x*(1.0 - x)\n",
    "    \n",
    "    def mse(self, target,output):\n",
    "        return np.average((target - output) ** 2)\n",
    "    \n",
    "    def gradient_descent(self, learningRate = 1):\n",
    "        #update the weight by stepping down the gradient\n",
    "        for i in range(len(self.weights)):\n",
    "            weights = self.weights[i]\n",
    "            derivatives =self.derivatives[i]\n",
    "            weights += derivatives * learningRate\n",
    "    def train(self, inputs, targets, epochs, learning_rate):\n",
    "        \n",
    "        #now enter the training data\n",
    "        for i in range(epochs):\n",
    "            sum_errors = 0\n",
    "            \n",
    "            #iter through all training data \n",
    "            for j, input in enumerate(inputs):\n",
    "                target = targets[j]\n",
    "                \n",
    "                #activate the network!\n",
    "                output = self.forward_propagte(input)\n",
    "                \n",
    "                error = target - output\n",
    "                \n",
    "                self.back_propagate(error)\n",
    "                \n",
    "                #perform gradient descent on derivate ##this will update weights\n",
    "                self.gradient_descent(learning_rate)\n",
    "                \n",
    "                #keep track of MSE for report later\n",
    "                sum_errors+= self.mse(target,output)\n",
    "            #Epoch complete , report the training error\n",
    "            print(\"ERROR: {} at each epoch {}\".format(sum_errors/len(items), i+1))\n",
    "        print(\"Training complete!\")\n",
    "        print(\"======\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = np.array([[random()/2 for _ in range(2)] for _ in range(1000)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = np.array([[i[0] + i[1]] for i in items])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create mlp with one hidden layer \n",
    "mlp = MLP(2, [5], 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ERROR: 0.04901593958420339 at each epoch 1\n",
      "ERROR: 0.039756727759117726 at each epoch 2\n",
      "ERROR: 0.039602475424942066 at each epoch 3\n",
      "ERROR: 0.03943845605968112 at each epoch 4\n",
      "ERROR: 0.03925286318155021 at each epoch 5\n",
      "ERROR: 0.03903282766451631 at each epoch 6\n",
      "ERROR: 0.03876365703325006 at each epoch 7\n",
      "ERROR: 0.038428126256752106 at each epoch 8\n",
      "ERROR: 0.03800582181892707 at each epoch 9\n",
      "ERROR: 0.03747263025814831 at each epoch 10\n",
      "ERROR: 0.036800557651099186 at each epoch 11\n",
      "ERROR: 0.03595820862324541 at each epoch 12\n",
      "ERROR: 0.03491243125335593 at each epoch 13\n",
      "ERROR: 0.033631770614514375 at each epoch 14\n",
      "ERROR: 0.03209226473562041 at each epoch 15\n",
      "ERROR: 0.03028542899801859 at each epoch 16\n",
      "ERROR: 0.02822678150555841 at each epoch 17\n",
      "ERROR: 0.025961424911857864 at each epoch 18\n",
      "ERROR: 0.023562587719612792 at each epoch 19\n",
      "ERROR: 0.021121338257783506 at each epoch 20\n",
      "ERROR: 0.018730354008770822 at each epoch 21\n",
      "ERROR: 0.01646814300722741 at each epoch 22\n",
      "ERROR: 0.014389406005824642 at each epoch 23\n",
      "ERROR: 0.01252322988198611 at each epoch 24\n",
      "ERROR: 0.010877060866718932 at each epoch 25\n",
      "ERROR: 0.009443115613630369 at each epoch 26\n",
      "ERROR: 0.00820463297988854 at each epoch 27\n",
      "ERROR: 0.0071407214667630935 at each epoch 28\n",
      "ERROR: 0.006229582545293199 at each epoch 29\n",
      "ERROR: 0.005450387395323568 at each epoch 30\n",
      "ERROR: 0.004784210067893681 at each epoch 31\n",
      "ERROR: 0.004214370784870223 at each epoch 32\n",
      "ERROR: 0.003726444956768857 at each epoch 33\n",
      "ERROR: 0.0033081029560320862 at each epoch 34\n",
      "ERROR: 0.002948878940390248 at each epoch 35\n",
      "ERROR: 0.00263992318417282 at each epoch 36\n",
      "ERROR: 0.0023737656433296993 at each epoch 37\n",
      "ERROR: 0.0021441030841314697 at each epoch 38\n",
      "ERROR: 0.0019456137057307624 at each epoch 39\n",
      "ERROR: 0.0017737988941664705 at each epoch 40\n",
      "ERROR: 0.0016248497669534407 at each epoch 41\n",
      "ERROR: 0.0014955354402135977 at each epoch 42\n",
      "ERROR: 0.0013831098655921969 at each epoch 43\n",
      "ERROR: 0.0012852343035924473 at each epoch 44\n",
      "ERROR: 0.001199912841244313 at each epoch 45\n",
      "ERROR: 0.0011254387310298873 at each epoch 46\n",
      "ERROR: 0.00106034967910574 at each epoch 47\n",
      "ERROR: 0.0010033905246203984 at each epoch 48\n",
      "ERROR: 0.0009534820224787061 at each epoch 49\n",
      "ERROR: 0.0009096946701584953 at each epoch 50\n",
      "Training complete!\n",
      "======\n"
     ]
    }
   ],
   "source": [
    "mlp.train(items, targets, 50 , 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dummy data \n",
    "input = np.array([0.3, 0.1])\n",
    "target = np.array([0.4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get a prediction\n",
    "output = mlp.forward_propagte(input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our network believes that 0.3 + 0.1 is equal to 0.41078154178626136\n"
     ]
    }
   ],
   "source": [
    "print(\"Our network believes that {} + {} is equal to {}\".format(input[0], input[1], output[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
